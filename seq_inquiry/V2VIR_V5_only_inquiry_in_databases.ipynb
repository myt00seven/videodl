{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20180930 Update\n",
    "\n",
    "- reorg codes\n",
    "\t- flex\n",
    "\t- clearness\n",
    "\t- we should memic the strucutr of DiDi's OD flow prediction model code:\n",
    "\t\t- one function -> build model (different model strucutre)\n",
    "\t\t- one function -> train the model (specify small/large UCF or other dataset)\n",
    "\t\t- oen function -> inquiry on UCF\n",
    "\t\t- one function get accuracy description and save to txt\n",
    "- run experiments\n",
    "\t- DTW vs. simple matching (need 2 differnt length of video in inquiry set)\n",
    "\t- ConvLSTM vs. LSTM vs. Conv2D (sort of frame based VGG ) vs. (VidSig) (Non-DL method)\n",
    "\n",
    "# A simple test for inquiry model\n",
    "\n",
    "\n",
    "Here is the setting:\n",
    "\n",
    "- My thought: Yintai Ma [09:23] \n",
    "  - Suppose I have a video X of 100 frames, denoting as X[0] to X[99]. We then split it to multiple clips without overlap. If then length of each clip is 5 frames, then we come up with a sequences of clips X[0:5],X[5:10],...,X[95:100]. We use the encoder to transfer the sequences of clips to sequences of embeddeds, reads y[0],y[1],...,y[20]. Now we randomly pick some frames from X as validation clip and transfer it into validation embedded y_hat. We want to see how y_hat is matching to the sequences of y[0]...y[20].\n",
    "\n",
    "- Diego:\n",
    "  - You have video X. Randomly pick  sequences of frames (non overlapping). Say x[4:10], x[34:37],x[85:95]. Now concatenate them into a single video. This is now your query. From here, create embedding sequence y[0],â€¦y[K]. Now do DTW of y against your encoded sequences of the videos in the database.\n",
    "  - This is subject to experimentation. I agree that there should be overlap. Overlap by half.\n",
    "\n",
    "- My thought: There are many variations for the implementation:\n",
    "  1. we keep overlaps for y. We transfer X[0:5],X[1:6],....X[94:99],X[95:100] into y[0]...y[100]. Now we want to see how y_hat is matching to y[].\n",
    "  2. When we pick some frames from X to composite validation clips, do we always pick 5 consecutive frames? Should we ever transfer X[0]+X[2:6] into y_hat?\n",
    "  3. How we match y_hat to y[] if y_hat is also a sequences? I think this is where DTW comes in right? If y_hat is just one embedded, then what we need is basically a simple comparison between the distance of two embedded. However, if y_hat is a sequences, say it has y_hat[0] and y_hat[1], then we will need to use DTW to consider the case where both y_hat[0] matches to y[0] and y_hat[1] matches to y[3] are the best query retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/_minimize.py:32: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/lbfgsb': missing __init__.py\n",
      "  from .lbfgsb import _minimize_lbfgsb\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/qhull': missing __init__.py\n",
      "  from .qhull import *\n"
     ]
    }
   ],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('/home/lab.analytics.northwestern.edu/yma/git/videodl/seq_inquiry'))\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "# from scipy.misc import toimage\n",
    "import pickle\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpngw\n",
    "import pandas as pd \n",
    "\n",
    "from IPython.display import HTML\n",
    "import random\n",
    "\n",
    "from mymodels import *\n",
    "from Video2videoInquiry import *\n",
    "\n",
    "import data_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Encoded embedding size: ', TensorShape([Dimension(None), Dimension(None), Dimension(7), Dimension(7), Dimension(8)]))\n",
      "--- Defining Decoder ---\n",
      "--- Finish Compile and Plot Model ---\n",
      "('The output dimension of encoder is:', TensorShape([Dimension(None), Dimension(None), Dimension(7), Dimension(7), Dimension(8)]))\n"
     ]
    }
   ],
   "source": [
    "LOAD_DATABASE_FROM_PKL = True\n",
    "\n",
    "# import conv_ae_config as config\n",
    "# model_file = \"ucf_vgg16_seq3_convlstm.001-0.0689.hdf5\" # encoding filter = 8\n",
    "# encoder, autoencoder =  ConvAutoEncoder(sequenceLength = config.sequenceLength)\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video500_conv_convlstm_8.pkl\"\n",
    "\n",
    "import simple_convlstm_ae_config as config\n",
    "setup = \"simple_convlstm\"\n",
    "model_file = \"ucf_seq3_simple_convlstm.003-0.0284.hdf5\" # encoding filter = 8\n",
    "encoder, autoencoder =  SimpleConvLstmAutoEncoder(sequenceLength = config.sequenceLength)\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video500_simple_convlstm_8.pkl\"\n",
    "database_file = \"/scratch/yma/data/inq_encoded_class100_video5000_simple_convlstm_8.pkl\"\n",
    "\n",
    "# import simple_conv_ae_config as config\n",
    "# setup = \"simple_conv\"\n",
    "# model_file = \"ucf_seq3_simple_conv.014-0.0114.hdf5\" # encoding filter = 8\n",
    "# encoder, autoencoder =  SimpleConvAutoEncoder(sequenceLength = config.sequenceLength)\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video500_simple_conv_8.pkl\"\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video5000_simple_conv_8.pkl\"\n",
    "\n",
    "# import simple_lstm_ae_config as config\n",
    "# setup = \"simple_lstm\"\n",
    "# model_file = \"ucf_seq3_simple_lstm.002-0.0726.hdf5\" # encoding filter = 8\n",
    "# encoder, autoencoder =  SimpleLstmAutoEncoder(sequenceLength = config.sequenceLength)\n",
    "# encoder, autoencoder =  SimpleLstmAutoEncoder(sequenceLength = config.sequenceLength)\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video500_simple_lstm_400.pkl\"\n",
    "# database_file = \"/scratch/yma/data/inq_encoded_class100_video5000_simple_lstm_400.pkl\"\n",
    "\n",
    "model_dir = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/\"\n",
    "data_path = \"/scratch/yma/git/five-video-classification-methods/data\"\n",
    "\n",
    "encoder.load_weights(os.path.join(model_dir, model_file), by_name=True)\n",
    "print(\"The output dimension of encoder is:\", encoder.output.shape)\n",
    "\n",
    "# for model_dict in models:\n",
    "#     print(\"Loading weights for setup:\", model_dict[\"setup\"])\n",
    "#     model_file = os.path.join(model_dir, model_dict[\"model_file\"])\n",
    "#     model_dict[\"encoder\"].load_weights(model_file, by_name=True)\n",
    "#     print(\"The output dimension of encoder is:\", model_dict[\"encoder\"].output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = config.sequenceLength\n",
    "# the number of frames in each clip\n",
    "\n",
    "# N_database = 500\n",
    "# N_database = 5\n",
    "# N_database = 50\n",
    "\n",
    "inq_length = 4\n",
    "# the number of clips in the inquiry, no overlap\n",
    "\n",
    "DATASET_CLASS_LIMIT = 100\n",
    "# number of class is the dataset\n",
    "\n",
    "DATASET_VIDEO_IN_CLASS_LIMIT = 50\n",
    "\n",
    "FLAG_RANDOM_CLASS = True\n",
    "# whether randomly pick classes in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Number of records in database:', 11881)\n",
      "('Number of records in filtered database:', 3383)\n",
      "Database Loaded.\n"
     ]
    }
   ],
   "source": [
    "data = initilize(encoder, data_path = data_path, \n",
    "                 seq_length = config.sequenceLength, \n",
    "                 class_limit = DATASET_CLASS_LIMIT, \n",
    "                 num_video_in_each_class = DATASET_VIDEO_IN_CLASS_LIMIT,\n",
    "                 random_class=FLAG_RANDOM_CLASS)\n",
    "\n",
    "with open(database_file, 'rb') as f:\n",
    "    database = pickle.load(f)\n",
    "print(\"Database Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Setup', 'TestNo', 'InqClip', 'NClass', 'NVideoinClassLimit', 'Method', 'Top1CH', 'Top2CH', 'Top3CH', 'Top4CH', 'Top5CH', 'Top6CH', 'Top7CH', 'Top8CH', 'Top9CH', 'Top10CH', 'Top1CS', 'Top2CS', 'Top3CS', 'Top4CS', 'Top5CS', 'Top6CS', 'Top7CS', 'Top8CS', 'Top9CS', 'Top10CS']\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "26 columns passed, passed data had 16 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-eb80cbec37ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mKinTopK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mdf_dtw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pd_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_VIDEO_IN_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKinTopK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dtw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-eb80cbec37ce>\u001b[0m in \u001b[0;36mmake_pd_df\u001b[0;34m(inq_dict, inq_result, database, DATASET_CLASS_LIMIT, DATASET_VIDEO_IN_CLASS_LIMIT, run_count, KinTopK, Method)\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mMethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                        ]+TopKClassHit, TopKClassScore], \n\u001b[0;32m---> 40\u001b[0;31m                  columns=df_columns)\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    367\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6250\u001b[0m         return _list_to_arrays(data, columns, coerce_float=coerce_float,\n\u001b[0;32m-> 6251\u001b[0;31m                                dtype=dtype)\n\u001b[0m\u001b[1;32m   6252\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6253\u001b[0m         return _list_of_dict_to_arrays(data, columns,\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6328\u001b[0m         \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6329\u001b[0m     return _convert_object_array(content, columns, dtype=dtype,\n\u001b[0;32m-> 6330\u001b[0;31m                                  coerce_float=coerce_float)\n\u001b[0m\u001b[1;32m   6331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_convert_object_array\u001b[0;34m(content, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m   6385\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6386\u001b[0m             raise AssertionError('%d columns passed, passed data had %s '\n\u001b[0;32m-> 6387\u001b[0;31m                                  'columns' % (len(columns), len(content)))\n\u001b[0m\u001b[1;32m   6388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6389\u001b[0m     \u001b[0;31m# provide soft conversion of object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 26 columns passed, passed data had 16 columns"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def ComputeTopK(inq_dict, inq_result, KinTopK):\n",
    "    TopKColumns = []\n",
    "    for i in range(1, KinTopK+1):\n",
    "        TopKColumns.append(\"Top%d\"%i+\"CH\") # ClassHit\n",
    "    for i in range(1, KinTopK+1):\n",
    "        TopKColumns.append(\"Top%d\"%i+\"CS\") # ClassScore\n",
    "    \n",
    "    TopKClassHit = []\n",
    "    for i in range(0, KinTopK):\n",
    "        if get_category(inq_result[\"scores\"][i][1]) == get_category(inq_dict[\"smp\"][2]):\n",
    "            TopKClassHit.append(1)\n",
    "        else:\n",
    "            TopKClassHit.append(0)\n",
    "            \n",
    "    TopKClassScore = []\n",
    "    for i in range(0, KinTopK):\n",
    "        TopKClassScore.append(inq_result[\"scores\"][i][0])\n",
    "        \n",
    "    return TopKColumns, TopKClassHit, TopKClassScore\n",
    "\n",
    "def make_pd_df(inq_dict, inq_result, database, DATASET_CLASS_LIMIT, \n",
    "               DATASET_VIDEO_IN_CLASS_LIMIT, run_count, KinTopK, Method):\n",
    "    TopKColumns, TopKClassHit, TopKClassScore = ComputeTopK(inq_dict, inq_result, KinTopK)\n",
    "    df_columns = [\"Setup\", \n",
    "                  \"TestNo\",\n",
    "                 \"InqClip\",\n",
    "                  \"NClass\",\n",
    "                 \"NVideoinClassLimit\",\n",
    "                  \"Method\",\n",
    "                 ]+TopKColumns\n",
    "    print(df_columns)\n",
    "    df = pd.DataFrame([[setup, \n",
    "                        run_count,\n",
    "                       inq_dict[\"smp\"][2],\n",
    "                        DATASET_CLASS_LIMIT,\n",
    "                        DATASET_VIDEO_IN_CLASS_LIMIT,\n",
    "                        Method,\n",
    "                       ]+TopKClassHit+TopKClassScore], \n",
    "                 columns=df_columns)\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "KinTopK = 10\n",
    "df_dtw = make_pd_df(inq_dict, inq_result, database, DATASET_CLASS_LIMIT, DATASET_VIDEO_IN_CLASS_LIMIT, run_count, KinTopK, Method = \"dtw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'setup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-9f71ba94c9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minquiry_in_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minq_length\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mmatch_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dtw\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf_dtw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pd_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_VIDEO_IN_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mshow_inquriy_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_top_limit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-f16d7daf7933>\u001b[0m in \u001b[0;36mmake_pd_df\u001b[0;34m(inq_dict, inq_result, database, DATASET_CLASS_LIMIT, DATASET_VIDEO_IN_CLASS_LIMIT, run_count)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_pd_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minq_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minq_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDATASET_VIDEO_IN_CLASS_LIMIT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdf_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Setup\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"TestNo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     df = pd.DataFrame([[setup, run_count]], \n\u001b[0m\u001b[1;32m      5\u001b[0m                  columns=df_columns)\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'setup' is not defined"
     ]
    }
   ],
   "source": [
    "# inqs = get_inquiry(data, if_random = True)\n",
    "# seqY = inqs[1]\n",
    "\n",
    "KinTopK = 10\n",
    "\n",
    "run_count = 0\n",
    "\n",
    "inq_dict, inq_result = inquiry_in_database(encoder, data, database, config, inq_length = inq_length , match_method = \"dtw\")\n",
    "df_dtw = make_pd_df(inq_dict, inq_result, database, DATASET_CLASS_LIMIT, DATASET_VIDEO_IN_CLASS_LIMIT, run_count, KinTopK)\n",
    "show_inquriy_stats(inq_dict, inq_result, show_top_limit = KinTopK)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"*\"*20)\n",
    "print(\"*\"*20)\n",
    "\n",
    "run_count = 1\n",
    "\n",
    "inq_dict, inq_result = inquiry_in_database(encoder, data, database, config, \n",
    "                                           inq_length = inq_length, match_method = \"naive\", \n",
    "                                           Given_inquiry = True,\n",
    "                                           inq_dict = inq_dict)\n",
    "show_inquriy_stats(inq_dict, inq_result, show_top_limit = KinTopK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v_WallPushups_g02_c01\n",
      "v_WallPushups_g04_c01\n",
      "v_WallPushups_g05_c04\n",
      "v_WallPushups_g05_c03\n",
      "v_WallPushups_g06_c01\n",
      "v_WallPushups_g07_c01\n",
      "v_WallPushups_g06_c04\n",
      "v_WallPushups_g07_c06\n",
      "v_WallPushups_g07_c04\n",
      "v_WallPushups_g03_c03\n",
      "v_WallPushups_g02_c04\n",
      "v_WallPushups_g07_c02\n",
      "v_WallPushups_g03_c05\n",
      "v_WallPushups_g05_c01\n",
      "v_WallPushups_g04_c02\n",
      "v_WallPushups_g03_c04\n",
      "v_WallPushups_g06_c05\n",
      "v_WallPushups_g03_c02\n",
      "v_WallPushups_g01_c03\n",
      "v_WallPushups_g07_c03\n",
      "v_WallPushups_g07_c05\n",
      "v_WallPushups_g02_c03\n",
      "v_WallPushups_g06_c03\n",
      "v_WallPushups_g01_c02\n",
      "v_WallPushups_g06_c06\n",
      "v_WallPushups_g04_c03\n",
      "v_WallPushups_g02_c02\n",
      "v_WallPushups_g05_c05\n",
      "v_WallPushups_g06_c02\n",
      "v_WallPushups_g01_c01\n",
      "v_WallPushups_g01_c04\n",
      "v_WallPushups_g03_c01\n",
      "v_WallPushups_g06_c07\n",
      "v_WallPushups_g04_c04\n",
      "v_WallPushups_g05_c02\n"
     ]
    }
   ],
   "source": [
    "for i in database:\n",
    "    if \"WallPushups\" in i[1][2]:\n",
    "        print(i[1][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-39bb941d6c3f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# (top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg) = multiple_test(data, run_times=100, if_itself=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mres_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmultiple_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_run_for_each_database\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# (top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg) = multiple_test(data, run_times=100, if_itself=False)\n",
    "\n",
    "res_dict = multiple_test(models, test_run_for_each_database=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'HorseRiding', 'v_HorseRiding_g04_c02', '201']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
