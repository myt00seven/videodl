{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20180930 Update\n",
    "\n",
    "- reorg codes\n",
    "\t- flex\n",
    "\t- clearness\n",
    "\t- we should memic the strucutr of DiDi's OD flow prediction model code:\n",
    "\t\t- one function -> build model (different model strucutre)\n",
    "\t\t- one function -> train the model (specify small/large UCF or other dataset)\n",
    "\t\t- oen function -> inquiry on UCF\n",
    "\t\t- one function get accuracy description and save to txt\n",
    "- run experiments\n",
    "\t- DTW vs. simple matching (need 2 differnt length of video in inquiry set)\n",
    "\t- ConvLSTM vs. LSTM vs. Conv2D (sort of frame based VGG ) vs. (VidSig) (Non-DL method)\n",
    "\n",
    "# A simple test for inquiry model\n",
    "\n",
    "\n",
    "Here is the setting:\n",
    "\n",
    "- My thought: Yintai Ma [09:23] \n",
    "  - Suppose I have a video X of 100 frames, denoting as X[0] to X[99]. We then split it to multiple clips without overlap. If then length of each clip is 5 frames, then we come up with a sequences of clips X[0:5],X[5:10],...,X[95:100]. We use the encoder to transfer the sequences of clips to sequences of embeddeds, reads y[0],y[1],...,y[20]. Now we randomly pick some frames from X as validation clip and transfer it into validation embedded y_hat. We want to see how y_hat is matching to the sequences of y[0]...y[20].\n",
    "\n",
    "- Diego:\n",
    "  - You have video X. Randomly pick  sequences of frames (non overlapping). Say x[4:10], x[34:37],x[85:95]. Now concatenate them into a single video. This is now your query. From here, create embedding sequence y[0],â€¦y[K]. Now do DTW of y against your encoded sequences of the videos in the database.\n",
    "  - This is subject to experimentation. I agree that there should be overlap. Overlap by half.\n",
    "\n",
    "- My thought: There are many variations for the implementation:\n",
    "  1. we keep overlaps for y. We transfer X[0:5],X[1:6],....X[94:99],X[95:100] into y[0]...y[100]. Now we want to see how y_hat is matching to y[].\n",
    "  2. When we pick some frames from X to composite validation clips, do we always pick 5 consecutive frames? Should we ever transfer X[0]+X[2:6] into y_hat?\n",
    "  3. How we match y_hat to y[] if y_hat is also a sequences? I think this is where DTW comes in right? If y_hat is just one embedded, then what we need is basically a simple comparison between the distance of two embedded. However, if y_hat is a sequences, say it has y_hat[0] and y_hat[1], then we will need to use DTW to consider the case where both y_hat[0] matches to y[0] and y_hat[1] matches to y[3] are the best query retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('/home/lab.analytics.northwestern.edu/yma/git/videodl/seq_inquiry'))\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/_minimize.py:32: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/lbfgsb': missing __init__.py\n",
      "  from .lbfgsb import _minimize_lbfgsb\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/qhull': missing __init__.py\n",
      "  from .qhull import *\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LSTM, RepeatVector\n",
    "from keras.layers.wrappers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "# from scipy.misc import toimage\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpngw\n",
    "import pandas as pd \n",
    "\n",
    "from IPython.display import HTML\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_DATA = 1 \n",
    "LOG_DIR = \"../../tensorboard/log/\"\n",
    "EPOCH = 150\n",
    "sequenceLength = 3\n",
    "setup_name = \"clrmvsq_simple_vgg_a\"\n",
    "N_SAMPLES = 1000\n",
    "BATCHSIZE = 5\n",
    "ucf_generate_fps = 2  # The fps to sample from the original UCF data to generate the train and val set\n",
    "# data_path = \"../../data/UCF/\"\n",
    "data_path = \"/scratch/yma/git/five-video-classification-methods/data\"\n",
    "\n",
    "batch_size=20\n",
    "data_type = 'images'\n",
    "concat=False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"--- Start Assembling the Model ---\")\n",
    "\n",
    "# inputs = Input(shape=(sequenceLength,224,224,3))\n",
    "\n",
    "# # conved = TimeDistributed(Lambda(MyCNN), input_shape=(sequenceLength,40,40,1)) (inputs)\n",
    "\n",
    "# x = TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv1'), input_shape=(sequenceLength,224,224,3))(inputs)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2), name='block1_pool'))(x)\n",
    "# # x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "# x = TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv1'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2), name='block2_pool'))(x)\n",
    "# x = TimeDistributed(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv1'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2), name='block3_pool'))(x)\n",
    "# x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv1'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2), name='block4_pool'))(x)\n",
    "# x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv1'))(x)\n",
    "\n",
    "# # LSTM part\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2), name='block5_pool'))(x)\n",
    "# # x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "# encoded = ConvLSTM2D(filters=100, kernel_size=(3, 3),padding='same', return_sequences=True)(x)\n",
    "\n",
    "# encoder = Model(output=encoded,input=inputs)\n",
    "# # myoptmizer = RMSprop(lr=0.1, decay=1e-4)\n",
    "# # autoencoder.compile(loss='mean_squared_error', optimizer=myoptmizer)\n",
    "# encoder.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "# # plot_model(encoder, to_file='query_model.png', show_shapes=True)\n",
    "\n",
    "# print('--- Finish Compile and Plot Model ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "('Keyword argument not understood:', u'implementation')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-67fa8044d053>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# model_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_simple_vgg16_seq3_convlstm_c5.002-0.0186.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_seq3_convlstm_c5.001-0.0570.hdf5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/saving.pyc\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deserialize_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mopened_new_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/saving.pyc\u001b[0m in \u001b[0;36m_deserialize_model\u001b[0;34m(f, custom_objects, compile)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0mmodel_weights_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/saving.pyc\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    456\u001b[0m                         '`Sequential.from_config(config)`?')\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/__init__.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                     custom_objects=dict(list(_GLOBAL_CUSTOM_OBJECTS.items()) +\n\u001b[0;32m--> 145\u001b[0;31m                                         list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    146\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/network.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;31m# First, we create all layers and enqueue nodes to be processed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'layers'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0mprocess_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# Then we process nodes in order of layer depth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;31m# Nodes that cannot yet be processed (if the inbound node\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/network.pyc\u001b[0m in \u001b[0;36mprocess_layer\u001b[0;34m(layer_data)\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m             layer = deserialize_layer(layer_data,\n\u001b[0;32m-> 1008\u001b[0;31m                                       custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m   1009\u001b[0m             \u001b[0mcreated_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/__init__.pyc\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                     printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/utils/generic_utils.pyc\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    145\u001b[0m                                         list(custom_objects.items())))\n\u001b[1;32m    146\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;31m# Then `cls` may be a function returning a class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/convolutional_recurrent.pyc\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/convolutional_recurrent.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, recurrent_activation, use_bias, kernel_initializer, recurrent_initializer, bias_initializer, unit_forget_bias, kernel_regularizer, recurrent_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, recurrent_constraint, bias_constraint, return_sequences, go_backwards, stateful, dropout, recurrent_dropout, **kwargs)\u001b[0m\n\u001b[1;32m    959\u001b[0m                                          \u001b[0mgo_backwards\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgo_backwards\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m                                          \u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m                                          **kwargs)\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivity_regularizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/convolutional_recurrent.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m                                         \u001b[0mstateful\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m                                         \u001b[0munroll\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m                                         **kwargs)\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mInputSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/layers/recurrent.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cell, return_sequences, return_state, go_backwards, stateful, unroll, **kwargs)\u001b[0m\n\u001b[1;32m    406\u001b[0m                              \u001b[0;34m'(tuple of integers, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m                              'one integer per RNN state).')\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/keras/engine/base_layer.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keyword argument not understood:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', u'implementation')"
     ]
    }
   ],
   "source": [
    "# weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_simple_vgg16_seq3_convlstm_c5.002-0.0186.hdf5\"\n",
    "# encoder.load_weights(weights_file, by_name=True)\n",
    "\n",
    "\n",
    "# model_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_simple_vgg16_seq3_convlstm_c5.002-0.0186.hdf5\"\n",
    "model_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_seq3_convlstm_c5.001-0.0570.hdf5\"\n",
    "encoder = load_model(model_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 3\n",
    "# the number of frames in each clip\n",
    "\n",
    "# N_database = 500\n",
    "# N_database = 5\n",
    "N_database = 50\n",
    "\n",
    "inq_length = 8\n",
    "# the number of clips in the inquiry, no overlap\n",
    "\n",
    "DATASET_CLASS_LIMIT = 50\n",
    "# number of class is the dataset\n",
    "\n",
    "FLAG_RANDOM_CLASS = True\n",
    "# whether randomly pick classes in the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_database(data):\n",
    "    database = []\n",
    "    for i in range(0, N_database):\n",
    "        smp = data.data[i]\n",
    "        # ['train', 'BaseballPitch', 'v_BaseballPitch_g25_c06', '123']\n",
    "        vid_len = int(smp[3])\n",
    "        frams = data.get_frames_for_sample(smp,data.data_dir)\n",
    "        seq = data.build_image_sequence(frams)\n",
    "        seq = np.array(seq)\n",
    "        seqX = []\n",
    "        print('Idx:', \"%d/%d\"%(i, N_database),  smp[2], 'Length:' , len(seq)-SEQ_LENGTH,'Jump:', (SEQ_LENGTH>>1)+1 )\n",
    "        for j in range(0,len(seq)-SEQ_LENGTH, (SEQ_LENGTH>>1)+1):\n",
    "            seqX.append(seq[j:j+SEQ_LENGTH])\n",
    "        seqX = np.array(seqX)\n",
    "        seqY = encoder.predict(seqX)\n",
    "        database.append((seqY, smp[2]))\n",
    "    return database\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_inquiry(data, if_random=True, pos = 0):\n",
    "    if if_random:\n",
    "        index = np.random.choice(len(data.data))\n",
    "        smp = data.data[index]\n",
    "    else:\n",
    "        smp = data.data[pos]\n",
    "    \n",
    "    vid_len = int(smp[3])\n",
    "    frams = data.get_frames_for_sample(smp, data.data_dir)\n",
    "    frams = data.rescale_list(frams, vid_len-1)\n",
    "    seq = data.build_image_sequence(frams)\n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seqX = []\n",
    "    X_frames_start= []\n",
    "    stepsize = vid_len / inq_length - 2\n",
    "    for j in range(0, inq_length):\n",
    "        jst = j*stepsize\n",
    "        jend = j*stepsize+SEQ_LENGTH\n",
    "        seqX.append(seq[jst:jend])\n",
    "        X_frames_start.append((jst, jend))\n",
    "    seqX = np.array(seqX)\n",
    "    seqY = encoder.predict(seqX)\n",
    "    return (seqX, seqY ,smp[2], X_frames_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(vec_i, vec_j):\n",
    "    return np.linalg.norm(vec_i - vec_j, ord=1)\n",
    "\n",
    "    \n",
    "def sum_dist(vecs_i, vecs_j):\n",
    "    assert len(vecs_i) == len(vecs_j)\n",
    "    _sum = 0\n",
    "    for i in range(0, len(vecs_i)):\n",
    "        _sum += get_dist( vecs_i[i], vecs_j[i])\n",
    "    return _sum\n",
    "\n",
    "    \n",
    "def get_next_ij(dist, i , j):\n",
    "    moves = [(0,-1), (-1,0), (-1,-1)]\n",
    "    min_value = np.inf\n",
    "    best_inci = -1 if i >0 else 0\n",
    "    best_incj = -1 if j >0 else 0\n",
    "    for (inci, incj) in moves:\n",
    "        if i+inci >= 0 and j+incj >=0 and dist[i+inci, j+incj] < min_value:\n",
    "            (best_inci, best_incj) = (inci, incj)\n",
    "            min_value = dist[i+inci, j+incj]\n",
    "    return (i+best_inci, j+best_incj)\n",
    "        \n",
    "def getBestDTWRoute(dist):\n",
    "    (i,j) = dist.shape\n",
    "    i=i-1\n",
    "    j=j-1\n",
    "    route = []\n",
    "    path_i = []\n",
    "    path_j = []\n",
    "    while i!=0 or j!=0:\n",
    "        route.append( (i,j) )\n",
    "        path_i.append(i)\n",
    "        path_j.append(j)\n",
    "        i_next, j_next = get_next_ij(dist,i,j)\n",
    "        (i,j) = (i_next, j_next)\n",
    "#     for combos in route:\n",
    "#         print(combos, \"->\")\n",
    "#     path_i = path_i.reverse()\n",
    "#     path_j = path_j.reverse()\n",
    "    return (np.array(path_i), np.array(path_j))\n",
    "        \n",
    "def DTWdistance(s1,s2):\n",
    "    n1 = len(s1)\n",
    "    n2 = len(s2)\n",
    "    dist = np.zeros((n1,n2))\n",
    "    cost = np.zeros((n1,n2))\n",
    "    dist[:,0] = np.inf\n",
    "    dist[0,:] = np.inf\n",
    "    dist[0,0] = 0\n",
    "#     print(\"n1 n2\", n1, n2)\n",
    "    for i in range(0,n1):\n",
    "        for j in range(0,n2):\n",
    "#             print(i,j)\n",
    "            cost[i,j] = get_dist(s1[i], s2[j])\n",
    "            dist[i,j] = cost[i,j] + min(dist[i-1,j], dist[i,j-1], dist[i-1,j-1])\n",
    "    path = getBestDTWRoute(dist)\n",
    "    return dist[n1-1, n2-1], cost, dist, path\n",
    "\n",
    "def NaiveMatch(cost):\n",
    "    (n,m) = cost.shape\n",
    "    min_sum = np.inf\n",
    "    assert n<m\n",
    "    for startj in range(0, m-n+1):\n",
    "        _sum = 0\n",
    "        starti = 0\n",
    "        for pos in range(0, n):\n",
    "            _sum += cost[starti+pos, startj+pos]\n",
    "        if _sum < min_sum:\n",
    "            min_sum = _sum\n",
    "    return min_sum\n",
    "    \n",
    "\n",
    "def inquiry_in_database(inquiry_seqY, database, match_method = \"dtw\"):\n",
    "    scores= []\n",
    "    score_names = []\n",
    "    bestscore = 1<<30\n",
    "#     dist, cost, acc, path\n",
    "    for i in database:\n",
    "#         print(inquiry_seqY.shape) 8 * 14470\n",
    "#         print(i[0].shape) ~50 * 14470\n",
    "        seqyflat = inquiry_seqY.reshape((inquiry_seqY.shape[0], -1))\n",
    "        iyflat = i[0].reshape((i[0].shape[0], -1))\n",
    "        dist, cost, acc, path = DTWdistance(seqyflat, iyflat)            \n",
    "        if match_method == \"dtw\":\n",
    "            dist = dist\n",
    "        elif match_method == \"naive\":\n",
    "            # slide the inqury sequence over the candidate video to find the minimal match position\n",
    "            dist = NaiveMatch(cost)\n",
    "            \n",
    "        scores.append((dist,i[1]))\n",
    "        if dist< bestscore:\n",
    "            bestscore = dist\n",
    "            bestpath = path\n",
    "            bestacc= acc\n",
    "            bestfilename = i[1]\n",
    "            \n",
    "    scores = sorted(scores, key=lambda x:x[0])\n",
    "    \n",
    "    res_dict = {}\n",
    "    res_dict[\"bestscore\"] = bestscore\n",
    "    res_dict[\"bestacc\"] = bestacc\n",
    "    res_dict[\"bestpath\"] = bestpath\n",
    "    res_dict[\"bestfilename\"] = bestfilename\n",
    "    res_dict[\"scores\"] = scores\n",
    "    return res_dict\n",
    "\n",
    "def show_inquriy_stats(inqs, inq_result, show_top_limit = 10):\n",
    "    print(\"Inqury is:\\t\"+ inqs[2])\n",
    "    print(\"Inqury frames:\\t\"+ str(inqs[3]))\n",
    "    print(\"Best Match is:\\t\"+ inq_result[\"bestfilename\"])\n",
    "    print(\"Best Dist:\\t\"+ str(inq_result[\"bestscore\"]))\n",
    "\n",
    "    acc = inq_result[\"bestacc\"]\n",
    "    path = inq_result[\"bestpath\"]\n",
    "    imshow(acc.T, origin='lower', cmap=cm.gray, interpolation='nearest')\n",
    "    plot(path[0], path[1], 'w')\n",
    "    # xlim((-0.5, acc.shape[0]-0.5))\n",
    "    # ylim((-0.5, acc.shape[1]-0.5))\n",
    "\n",
    "    print(\"========================\")\n",
    "    print(\"All scores in database:\")\n",
    "    for i in range( min(show_top_limit, len(inq_result[\"scores\"])) ):\n",
    "        print(\"Record: \"+ inq_result[\"scores\"][i][1].ljust(25)+ \"\\tDTW Dist: \"+ str(inq_result[\"scores\"][i][0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initilize(data_path = data_path, seq_length=SEQ_LENGTH, class_limit=DATASET_CLASS_LIMIT, random_class = FLAG_RANDOM_CLASS):\n",
    "    # Initilize \n",
    "\n",
    "    import data_seq\n",
    "    from scipy.spatial.distance import euclidean\n",
    "    from dtw import dtw\n",
    "    %pylab inline\n",
    "\n",
    "    data_seq = reload(data_seq)\n",
    "    data = data_seq.DataSet(data_dir = data_path, seq_length=seq_length,class_limit=class_limit, random_class=random_class)\n",
    "    random.shuffle(data.data)\n",
    "    print(\"Number of records in database:\", len(data.data))\n",
    "    database = create_database(data)\n",
    "    # database.append((seqY, smp[2]))\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(str):\n",
    "    return str.split('_')[1]\n",
    "def multiple_test(data,run_times=100, if_itself=True):\n",
    "    # how many top result will be counted\n",
    "    Count_tops = 5\n",
    "    \n",
    "    Total_run = run_times\n",
    "    # Tops_same_count: number of same category as inq appeared in result list\n",
    "    Tops_same_count = [0.0] * Count_tops\n",
    "\n",
    "    # Tops_same_ever_hit: if the same category as inq has appeared in result list of top N\n",
    "    Tops_same_ever_hit = [0.0] * Count_tops\n",
    "    \n",
    "    # Sum of Score of Nth element of return list\n",
    "    Nth_score_sum = [0.0] * Count_tops\n",
    "    Hit_itself_sum = [0.0] * Count_tops\n",
    "    self_pos_sum = 0\n",
    "    \n",
    "    run_times = min(run_times, len(data.data)-N_database)\n",
    "\n",
    "    if if_itself:\n",
    "        stpos = 0\n",
    "    else:\n",
    "        stpos = N_database\n",
    "#     print(stpos)\n",
    "    \n",
    "    for i in range(0, run_times):\n",
    "        if i %1 == 0:\n",
    "            print(\"%d/%d Runs.\"%(i, run_times))\n",
    "            \n",
    "        inqs = get_inquiry(data, if_random = False, pos= stpos+i)\n",
    "        seqY = inqs[1]\n",
    "        inq_result = inquiry_in_database(seqY, database)\n",
    "        for j in range(0, Count_tops):\n",
    "            if(get_category(inq_result[\"scores\"][j][1]) == get_category(inqs[2])):\n",
    "                for k in range(j, Count_tops):\n",
    "                    Tops_same_count[k] += 1\n",
    "#                 break\n",
    "\n",
    "        for j in range(0, Count_tops):\n",
    "            if(get_category(inq_result[\"scores\"][j][1]) == get_category(inqs[2])):\n",
    "                for k in range(j, Count_tops):\n",
    "                    Tops_same_ever_hit[k] += 1\n",
    "                break\n",
    "            \n",
    "                \n",
    "        for j in range(0, Count_tops):\n",
    "            Nth_score_sum[j] += inq_result[\"scores\"][j][0]\n",
    "            if(inq_result[\"scores\"][j][1] == inqs[2]):\n",
    "                Hit_itself_sum[j] += 1\n",
    "            \n",
    "    top_cat_same = [x/Total_run for x in Tops_same_count]\n",
    "    top_cat_same_hit = [x/Total_run for x in Tops_same_ever_hit]\n",
    "    Nth_score_avg = [x/Total_run for x in Nth_score_sum]\n",
    "    Hit_itself_avg = [x/Total_run for x in Hit_itself_sum]\n",
    "    \n",
    "    res_dict = {}\n",
    "    res_dict[\"top_cat_same\"] = top_cat_same\n",
    "    res_dict[\"top_cat_same_hit\"] = top_cat_same_hit\n",
    "    res_dict[\"Nth_score_avg\"] = Nth_score_avg\n",
    "    res_dict[\"Hit_itself_avg\"] = Hit_itself_avg\n",
    "    \n",
    "    print(\"top_cat_same: \", top_cat_same)\n",
    "    print(\"top_cat_same_hit: \", top_cat_same_hit)\n",
    "    print(\"Nth_score_avg: \", Nth_score_avg)\n",
    "    print(\"Hit_itself_avg: \", Hit_itself_avg)\n",
    "    \n",
    "    return res_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "('Number of records in database:', 5897)\n",
      "('Idx:', '0/50', 'v_SkateBoarding_g15_c02', 'Length:', 127, 'Jump:', 2)\n",
      "('Idx:', '1/50', 'v_HammerThrow_g06_c03', 'Length:', 157, 'Jump:', 2)\n",
      "('Idx:', '2/50', 'v_Archery_g24_c02', 'Length:', 239, 'Jump:', 2)\n",
      "('Idx:', '3/50', 'v_YoYo_g08_c01', 'Length:', 186, 'Jump:', 2)\n",
      "('Idx:', '4/50', 'v_JavelinThrow_g23_c04', 'Length:', 133, 'Jump:', 2)\n",
      "('Idx:', '5/50', 'v_HeadMassage_g20_c05', 'Length:', 103, 'Jump:', 2)\n",
      "('Idx:', '6/50', 'v_YoYo_g14_c04', 'Length:', 163, 'Jump:', 2)\n",
      "('Idx:', '7/50', 'v_WritingOnBoard_g15_c05', 'Length:', 226, 'Jump:', 2)\n",
      "('Idx:', '8/50', 'v_UnevenBars_g17_c03', 'Length:', 132, 'Jump:', 2)\n",
      "('Idx:', '9/50', 'v_GolfSwing_g25_c02', 'Length:', 127, 'Jump:', 2)\n",
      "('Idx:', '10/50', 'v_HeadMassage_g18_c04', 'Length:', 257, 'Jump:', 2)\n",
      "('Idx:', '11/50', 'v_HandstandWalking_g15_c03', 'Length:', 203, 'Jump:', 2)\n",
      "('Idx:', '12/50', 'v_Basketball_g09_c03', 'Length:', 82, 'Jump:', 2)\n",
      "('Idx:', '13/50', 'v_YoYo_g03_c06', 'Length:', 190, 'Jump:', 2)\n",
      "('Idx:', '14/50', 'v_Archery_g25_c01', 'Length:', 206, 'Jump:', 2)\n",
      "('Idx:', '15/50', 'v_Skiing_g13_c03', 'Length:', 181, 'Jump:', 2)\n",
      "('Idx:', '16/50', 'v_BoxingSpeedBag_g03_c04', 'Length:', 145, 'Jump:', 2)\n",
      "('Idx:', '17/50', 'v_Knitting_g01_c02', 'Length:', 237, 'Jump:', 2)\n",
      "('Idx:', '18/50', 'v_HorseRace_g15_c03', 'Length:', 264, 'Jump:', 2)\n",
      "('Idx:', '19/50', 'v_Knitting_g01_c03', 'Length:', 272, 'Jump:', 2)\n",
      "('Idx:', '20/50', 'v_PlayingGuitar_g08_c04', 'Length:', 247, 'Jump:', 2)\n",
      "('Idx:', '21/50', 'v_JumpingJack_g20_c03', 'Length:', 137, 'Jump:', 2)\n",
      "('Idx:', '22/50', 'v_SkateBoarding_g10_c05', 'Length:', 96, 'Jump:', 2)\n",
      "('Idx:', '23/50', 'v_FrontCrawl_g22_c04', 'Length:', 150, 'Jump:', 2)\n",
      "('Idx:', '24/50', 'v_HandstandWalking_g17_c03', 'Length:', 151, 'Jump:', 2)\n",
      "('Idx:', '25/50', 'v_TrampolineJumping_g25_c04', 'Length:', 148, 'Jump:', 2)\n",
      "('Idx:', '26/50', 'v_YoYo_g10_c05', 'Length:', 169, 'Jump:', 2)\n",
      "('Idx:', '27/50', 'v_Skiing_g03_c02', 'Length:', 107, 'Jump:', 2)\n",
      "('Idx:', '28/50', 'v_CricketBowling_g15_c06', 'Length:', 72, 'Jump:', 2)\n",
      "('Idx:', '29/50', 'v_ThrowDiscus_g24_c03', 'Length:', 83, 'Jump:', 2)\n",
      "('Idx:', '30/50', 'v_Nunchucks_g10_c06', 'Length:', 163, 'Jump:', 2)\n",
      "('Idx:', '31/50', 'v_PlayingDhol_g07_c04', 'Length:', 251, 'Jump:', 2)\n",
      "('Idx:', '32/50', 'v_JumpingJack_g20_c01', 'Length:', 117, 'Jump:', 2)\n",
      "('Idx:', '33/50', 'v_WritingOnBoard_g23_c03', 'Length:', 148, 'Jump:', 2)\n",
      "('Idx:', '34/50', 'v_SkateBoarding_g07_c02', 'Length:', 196, 'Jump:', 2)\n",
      "('Idx:', '35/50', 'v_WallPushups_g19_c01', 'Length:', 85, 'Jump:', 2)\n",
      "('Idx:', '36/50', 'v_YoYo_g08_c05', 'Length:', 173, 'Jump:', 2)\n",
      "('Idx:', '37/50', 'v_JavelinThrow_g02_c04', 'Length:', 139, 'Jump:', 2)\n",
      "('Idx:', '38/50', 'v_Archery_g08_c02', 'Length:', 113, 'Jump:', 2)\n",
      "('Idx:', '39/50', 'v_JavelinThrow_g09_c01', 'Length:', 113, 'Jump:', 2)\n",
      "('Idx:', '40/50', 'v_FieldHockeyPenalty_g10_c04', 'Length:', 165, 'Jump:', 2)\n",
      "('Idx:', '41/50', 'v_FieldHockeyPenalty_g09_c02', 'Length:', 198, 'Jump:', 2)\n",
      "('Idx:', '42/50', 'v_Bowling_g03_c01', 'Length:', 157, 'Jump:', 2)\n",
      "('Idx:', '43/50', 'v_JumpingJack_g13_c05', 'Length:', 94, 'Jump:', 2)\n",
      "('Idx:', '44/50', 'v_JavelinThrow_g16_c02', 'Length:', 129, 'Jump:', 2)\n",
      "('Idx:', '45/50', 'v_WallPushups_g19_c04', 'Length:', 83, 'Jump:', 2)\n",
      "('Idx:', '46/50', 'v_JumpingJack_g04_c02', 'Length:', 75, 'Jump:', 2)\n",
      "('Idx:', '47/50', 'v_WritingOnBoard_g21_c05', 'Length:', 218, 'Jump:', 2)\n",
      "('Idx:', '48/50', 'v_PlayingSitar_g15_c02', 'Length:', 100, 'Jump:', 2)\n",
      "('Idx:', '49/50', 'v_SkateBoarding_g13_c02', 'Length:', 108, 'Jump:', 2)\n"
     ]
    }
   ],
   "source": [
    "database = initilize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inqury is:\tv_HandStandPushups_g25_c01\n",
      "Inqury frames:\t[(0, 3), (15, 18), (30, 33), (45, 48), (60, 63), (75, 78), (90, 93), (105, 108)]\n",
      "Best Match is:\tv_WallPushups_g19_c01\n",
      "Best Dist:\t23197.532470703125\n",
      "========================\n",
      "All scores in database:\n",
      "Record: v_WallPushups_g19_c01    \tDTW Dist: 23197.532470703125\n",
      "Record: v_WallPushups_g19_c04    \tDTW Dist: 23317.1748046875\n",
      "Record: v_PlayingDhol_g07_c04    \tDTW Dist: 24242.6728515625\n",
      "Record: v_WritingOnBoard_g23_c03 \tDTW Dist: 24594.572265625\n",
      "Record: v_WritingOnBoard_g15_c05 \tDTW Dist: 25441.063232421875\n",
      "********************\n",
      "********************\n",
      "********************\n",
      "Inqury is:\tv_HandStandPushups_g25_c01\n",
      "Inqury frames:\t[(0, 3), (15, 18), (30, 33), (45, 48), (60, 63), (75, 78), (90, 93), (105, 108)]\n",
      "Best Match is:\tv_WallPushups_g19_c01\n",
      "Best Dist:\t22134.832275390625\n",
      "========================\n",
      "All scores in database:\n",
      "Record: v_WallPushups_g19_c01    \tDTW Dist: 22134.832275390625\n",
      "Record: v_WallPushups_g19_c04    \tDTW Dist: 22166.397216796875\n",
      "Record: v_PlayingDhol_g07_c04    \tDTW Dist: 23328.9404296875\n",
      "Record: v_WritingOnBoard_g23_c03 \tDTW Dist: 23504.2373046875\n",
      "Record: v_WritingOnBoard_g15_c05 \tDTW Dist: 25123.349853515625\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAE4AAAD8CAYAAADZqJJjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncEZcOCMunJH/A6upzUOyAF7OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa7686fc4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inqs = get_inquiry(data, if_random = True)\n",
    "\n",
    "seqY = inqs[1]\n",
    "inq_result = inquiry_in_database(seqY, database)\n",
    "show_inquriy_stats(inqs, inq_result, show_top_limit = 5)\n",
    "\n",
    "print(\"*\"*20)\n",
    "print(\"*\"*20)\n",
    "print(\"*\"*20)\n",
    "\n",
    "inq_result = inquiry_in_database(seqY, database, match_method = \"naive\")\n",
    "show_inquriy_stats(inqs, inq_result, show_top_limit = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/5 Runs.\n",
      "1/5 Runs.\n",
      "2/5 Runs.\n",
      "3/5 Runs.\n",
      "4/5 Runs.\n",
      "([0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0], [27576.09453125, 31657.386083984376, 34039.05859375, 40437.35498046875, 43974.799609375], [0.0, 0.0, 0.0, 0.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "# (top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg) = multiple_test(data, run_times=100, if_itself=False)\n",
    "\n",
    "res_dict = multiple_test(data, run_times=5, if_itself=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 100 yes\n",
    "# # ([1.0, 1.6, 1.9, 2.11, 2.31], \n",
    "# [1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "# [477.99725810013655, 1569.801293508719, 1983.8946612704194, 2173.4673165842296, 2239.76024740403],\n",
    "# [1.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 100 No it self\n",
    "# ([0.67, 1.07, 1.28, 1.5, 1.68], \n",
    "#  [0.67, 0.72, 0.75, 0.78, 0.78], \n",
    "#  [1468.9675286393074, 1990.4723390313206, 2219.1774095071487, 2314.7653604314573, 2373.6116836425554],\n",
    "#  [0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
