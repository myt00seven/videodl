{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20180930 Update\n",
    "\n",
    "- reorg codes\n",
    "\t- flex\n",
    "\t- clearness\n",
    "\t- we should memic the strucutr of DiDi's OD flow prediction model code:\n",
    "\t\t- one function -> build model (different model strucutre)\n",
    "\t\t- one function -> train the model (specify small/large UCF or other dataset)\n",
    "\t\t- oen function -> inquiry on UCF\n",
    "\t\t- one function get accuracy description and save to txt\n",
    "- run experiments\n",
    "\t- DTW vs. simple matching (need 2 differnt length of video in inquiry set)\n",
    "\t- ConvLSTM vs. LSTM vs. Conv2D (sort of frame based VGG ) vs. (VidSig) (Non-DL method)\n",
    "\n",
    "# A simple test for inquiry model\n",
    "\n",
    "\n",
    "Here is the setting:\n",
    "\n",
    "- My thought: Yintai Ma [09:23] \n",
    "  - Suppose I have a video X of 100 frames, denoting as X[0] to X[99]. We then split it to multiple clips without overlap. If then length of each clip is 5 frames, then we come up with a sequences of clips X[0:5],X[5:10],...,X[95:100]. We use the encoder to transfer the sequences of clips to sequences of embeddeds, reads y[0],y[1],...,y[20]. Now we randomly pick some frames from X as validation clip and transfer it into validation embedded y_hat. We want to see how y_hat is matching to the sequences of y[0]...y[20].\n",
    "\n",
    "- Diego:\n",
    "  - You have video X. Randomly pick  sequences of frames (non overlapping). Say x[4:10], x[34:37],x[85:95]. Now concatenate them into a single video. This is now your query. From here, create embedding sequence y[0],â€¦y[K]. Now do DTW of y against your encoded sequences of the videos in the database.\n",
    "  - This is subject to experimentation. I agree that there should be overlap. Overlap by half.\n",
    "\n",
    "- My thought: There are many variations for the implementation:\n",
    "  1. we keep overlaps for y. We transfer X[0:5],X[1:6],....X[94:99],X[95:100] into y[0]...y[100]. Now we want to see how y_hat is matching to y[].\n",
    "  2. When we pick some frames from X to composite validation clips, do we always pick 5 consecutive frames? Should we ever transfer X[0]+X[2:6] into y_hat?\n",
    "  3. How we match y_hat to y[] if y_hat is also a sequences? I think this is where DTW comes in right? If y_hat is just one embedded, then what we need is basically a simple comparison between the distance of two embedded. However, if y_hat is a sequences, say it has y_hat[0] and y_hat[1], then we will need to use DTW to consider the case where both y_hat[0] matches to y[0] and y_hat[1] matches to y[3] are the best query retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('/home/lab.analytics.northwestern.edu/yma/git/videodl/seq_inquiry'))\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/_minimize.py:32: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/optimize/lbfgsb': missing __init__.py\n",
      "  from .lbfgsb import _minimize_lbfgsb\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/__init__.py:95: ImportWarning: Not importing directory '/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/scipy/spatial/qhull': missing __init__.py\n",
      "  from .qhull import *\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LSTM, RepeatVector\n",
    "from keras.layers.wrappers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "# from scipy.misc import toimage\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpngw\n",
    "import pandas as pd \n",
    "\n",
    "from IPython.display import HTML\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_DATA = 1 \n",
    "LOG_DIR = \"../../tensorboard/log/\"\n",
    "EPOCH = 150\n",
    "sequenceLength = 3\n",
    "setup_name = \"clrmvsq_simple_vgg_a\"\n",
    "N_SAMPLES = 1000\n",
    "BATCHSIZE = 5\n",
    "ucf_generate_fps = 2  # The fps to sample from the original UCF data to generate the train and val set\n",
    "# data_path = \"../../data/UCF/\"\n",
    "data_path = \"/scratch/yma/git/five-video-classification-methods/data\"\n",
    "\n",
    "batch_size=20\n",
    "data_type = 'images'\n",
    "concat=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([['train', 'BasketballDunk', 'v_BasketballDunk_g20_c02', '53']], '\\n')\n",
      "['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam']\n",
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import data_seq\n",
    "# from importlib import reload\n",
    "data_seq = reload(data_seq)\n",
    "\n",
    "data = data_seq.DataSet(data_dir = data_path, seq_length=5,class_limit=10)\n",
    "\n",
    "print (data.data[:1], '\\n')\n",
    "print (data.classes[:5])\n",
    "print (data.image_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-310939ea36bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frames_for_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/scratch/yma/git/videodl/seq_inquiry/data_seq.py\u001b[0m in \u001b[0;36mget_frames_for_sample\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \"\"\"Given a sample row from the data file, get all the corresponding frame\n\u001b[1;32m    276\u001b[0m         filenames.\"\"\"\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;31m#         path =  +  + '/' + sample[1] + '/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;31m#         filename = sample[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "train, test = data.split_train_test()\n",
    "sample = random.choice(train)\n",
    "frames = data.get_frames_for_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show 'data' shape:\n",
      "944\n",
      "Show 'data' first element:\n",
      "['train', 'BasketballDunk', 'v_BasketballDunk_g20_c02', '53']\n",
      "Creating train generator with 944 videos.\n",
      "Recommended steps per epoch = videos/batch_size\n",
      "0\n",
      "5\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0cf4f9c5230f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/yma/git/videodl/seq_inquiry/data_seq.py\u001b[0m in \u001b[0;36mseq_generator\u001b[0;34m(self, batch_size, train_test, data_type, concat)\u001b[0m\n\u001b[1;32m    175\u001b[0m                     \u001b[0;31m# print(\"seq_length:%d\"%self.seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m                     \u001b[0;31m# print(self.seq_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrescale_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                     \u001b[0;31m# Build the image sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/yma/git/videodl/seq_inquiry/data_seq.py\u001b[0m in \u001b[0;36mrescale_list\u001b[0;34m(input_list, size)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Get the number to skip between iterations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator = data.seq_generator(batch_size, 'train', 'images')\n",
    "\n",
    "X,y  = next(generator);\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "images = X[18]\n",
    "imageio.mimsave('./movie.gif', images)\n",
    "HTML('<img src=\"./movie.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y  = next(generator);\n",
    "# for i in range (0,5):\n",
    "#     images = X[i][0]\n",
    "#     plt.imshow(images)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d56702b83b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    X,y  = next(generator);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y  = next(generator);\n",
    "\n",
    "print(X.shape)\n",
    "\n",
    "images = X[18]\n",
    "imageio.mimsave('./movie.gif', images)\n",
    "HTML('<img src=\"./movie.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Must Run from here: Adjust the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examaine model file\n",
    "from keras.models import load_model\n",
    "\n",
    "# weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_seq3_convlstm.040-0.0857.hdf5\"\n",
    "\n",
    "weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_simple_seq3_convlstm.001-0.03.hdf5\"\n",
    "\n",
    "model = load_model(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-e4ea706a7cfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Start Assembling the Model ---\")\n",
    "\n",
    "inputs = Input(shape=(sequenceLength,224,224,3))\n",
    "\n",
    "# conved = TimeDistributed(Lambda(MyCNN), input_shape=(sequenceLength,40,40,1)) (inputs)\n",
    "\n",
    "x = TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv1'), input_shape=(sequenceLength,224,224,3))(inputs)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block1_pool'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "x = TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block2_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block3_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block4_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv1'))(x)\n",
    "\n",
    "# LSTM part\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block5_pool'))(x)\n",
    "# x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "encoded = ConvLSTM2D(filters=100, kernel_size=(3, 3),padding='same', return_sequences=True)(x)\n",
    "\n",
    "encoder = Model(output=encoded,input=inputs)\n",
    "# myoptmizer = RMSprop(lr=0.1, decay=1e-4)\n",
    "# autoencoder.compile(loss='mean_squared_error', optimizer=myoptmizer)\n",
    "encoder.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "# plot_model(encoder, to_file='query_model.png', show_shapes=True)\n",
    "\n",
    "print('--- Finish Compile and Plot Model ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_simple_vgg16_seq3_convlstm_c5.002-0.0186.hdf5\"\n",
    "encoder.load_weights(weights_file, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 3\n",
    "# the number of frames in each clip\n",
    "\n",
    "N_database = 500\n",
    "\n",
    "inq_length = 8\n",
    "# the number of clips in the inquiry, no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_database(data):\n",
    "    database = []\n",
    "    for i in range(0, N_database):\n",
    "        smp = data.data[i]\n",
    "        # ['train', 'BaseballPitch', 'v_BaseballPitch_g25_c06', '123']\n",
    "        vid_len = int(smp[3])\n",
    "        frams = data.get_frames_for_sample(smp)\n",
    "# No need for this\n",
    "#         frams = data.rescale_list(frams, vid_len-1)\n",
    "        seq = data.build_image_sequence(frams)\n",
    "        seq = np.array(seq)\n",
    "        \n",
    "        seqX = []\n",
    "        print('Idx:',i,  smp[2], 'Length:' , len(seq)-SEQ_LENGTH,'Jump:', (SEQ_LENGTH>>1)+1 )\n",
    "        for j in range(0,len(seq)-SEQ_LENGTH, (SEQ_LENGTH>>1)+1):\n",
    "            seqX.append(seq[j:j+SEQ_LENGTH])\n",
    "        seqX = np.array(seqX)\n",
    "        seqY = encoder.predict(seqX)\n",
    "        database.append((seqY, smp[2]))\n",
    "    return database\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def get_inquiry(data, if_random=True, pos = 0):\n",
    "    if if_random:\n",
    "        smp = random.choice(data.data)\n",
    "    else:\n",
    "        smp = data.data[pos]\n",
    "    \n",
    "    vid_len = int(smp[3])\n",
    "    frams = data.get_frames_for_sample(smp)\n",
    "    frams = data.rescale_list(frams, vid_len-1)\n",
    "    seq = data.build_image_sequence(frams)\n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seqX = []\n",
    "    X_frames_start= []\n",
    "    stepsize = vid_len / inq_length - 2\n",
    "    for j in range(0, inq_length):\n",
    "        jst = j*stepsize\n",
    "        jend = j*stepsize+SEQ_LENGTH\n",
    "        seqX.append(seq[jst:jend])\n",
    "        X_frames_start.append((jst, jend))\n",
    "    seqX = np.array(seqX)\n",
    "    seqY = encoder.predict(seqX)\n",
    "    return (seqX, seqY ,smp[2], X_frames_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inquiry_in_database(inquiry_seqY, database):\n",
    "    scores= []\n",
    "    score_names = []\n",
    "    bestscore = 1<<30\n",
    "#     dist, cost, acc, path\n",
    "    for i in database:\n",
    "#         print(inquiry_seqY.shape)\n",
    "#         print(i[0].shape)\n",
    "        seqyflat = inquiry_seqY.reshape((inquiry_seqY.shape[0], 3*7*7*100))\n",
    "        iyflat = i[0].reshape((i[0].shape[0], 3*7*7*100))\n",
    "#         print(seqyflat.shape)\n",
    "#         print(iyflat.shape)\n",
    "        dist, cost, acc, path = dtw(seqyflat, iyflat, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "        scores.append((dist,i[1]))\n",
    "        if dist< bestscore:\n",
    "            bestscore = dist\n",
    "            bestpath = path\n",
    "            bestacc= acc\n",
    "            bestfilename = i[1]\n",
    "    scores = sorted(scores, key=lambda x:x[0])\n",
    "    return (bestscore, bestacc, bestpath, bestfilename, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/dl/lib/python2.7/site-packages/IPython/core/magics/pylab.py:161: UserWarning: pylab import has clobbered these variables: ['plt', 'random', 'copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'SEQ_LENGTH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33f79c6cb1a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_seq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_seq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEQ_LENGTH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclass_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SEQ_LENGTH' is not defined"
     ]
    }
   ],
   "source": [
    "import data_seq\n",
    "from scipy.spatial.distance import euclidean\n",
    "from dtw import dtw\n",
    "%pylab inline\n",
    "\n",
    "data_seq = reload(data_seq)\n",
    "data = data_seq.DataSet(seq_length=SEQ_LENGTH,class_limit=20, random_class=True)\n",
    "random.shuffle(data.data)\n",
    "print(len(data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-77c62ad0cbb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatabase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "database = create_database(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-fc187eed0669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inquiry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mif_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mseqY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0minq_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minquiry_in_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseqY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "inqs = get_inquiry(data, if_random = True)\n",
    "seqY = inqs[1]\n",
    "\n",
    "inq_result = inquiry_in_database(seqY, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inqs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-167bad0dfd9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inqury is:\\t\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0minqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Inqury frames:\\t\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Match is:\\t\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0minq_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Dist:\\t\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minq_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inqs' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Inqury is:\\t\"+ inqs[2])\n",
    "print(\"Inqury frames:\\t\"+ str(inqs[3]))\n",
    "print(\"Best Match is:\\t\"+ inq_result[3])\n",
    "print(\"Best Dist:\\t\"+ str(inq_result[0]))\n",
    "\n",
    "acc = inq_result[1]\n",
    "path = inq_result[2]\n",
    "imshow(acc.T, origin='lower', cmap=cm.gray, interpolation='nearest')\n",
    "plot(path[0], path[1], 'w')\n",
    "# xlim((-0.5, acc.shape[0]-0.5))\n",
    "# ylim((-0.5, acc.shape[1]-0.5))\n",
    "\n",
    "print(\"========================\")\n",
    "print(\"All scores in database:\")\n",
    "for i in range(len(inq_result[4])):\n",
    "    print(\"Record: \"+ inq_result[4][i][1].ljust(25)+ \"\\tDTW Dist: \"+ str(inq_result[4][i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category(str):\n",
    "    return str.split('_')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_test(data,run_times=100, if_itself=True):\n",
    "    # how top result will be counted\n",
    "    Count_tops = 5\n",
    "    \n",
    "    Total_run = run_times\n",
    "    # Tops_same_count: number of same category as inq appeared in result list\n",
    "    Tops_same_count = [0.0] * Count_tops\n",
    "\n",
    "    # Tops_same_ever_hit: if the same category as inq has appeared in result list of top N\n",
    "    Tops_same_ever_hit = [0.0] * Count_tops\n",
    "    \n",
    "    # Sum of Score of Nth element of return list\n",
    "    Nth_score_sum = [0.0] * Count_tops\n",
    "    Hit_itself_sum = [0.0] * Count_tops\n",
    "    self_pos_sum = 0\n",
    "    \n",
    "    run_times = min(run_times, len(data.data)-N_database)\n",
    "\n",
    "    if if_itself:\n",
    "        stpos = 0\n",
    "    else:\n",
    "        stpos = N_database\n",
    "#     print(stpos)\n",
    "    \n",
    "    for i in range(0, run_times):\n",
    "        inqs = get_inquiry(data, if_random = False, pos= stpos+i)\n",
    "        seqY = inqs[1]\n",
    "        inq_result = inquiry_in_database(seqY, database)\n",
    "        for j in range(0, Count_tops):\n",
    "            if(get_category(inq_result[4][j][1]) == get_category(inqs[2])):\n",
    "                for k in range(j, Count_tops):\n",
    "                    Tops_same_count[k] += 1\n",
    "#                 break\n",
    "\n",
    "        for j in range(0, Count_tops):\n",
    "            if(get_category(inq_result[4][j][1]) == get_category(inqs[2])):\n",
    "                for k in range(j, Count_tops):\n",
    "                    Tops_same_ever_hit[k] += 1\n",
    "                break\n",
    "            \n",
    "                \n",
    "        for j in range(0, Count_tops):\n",
    "            Nth_score_sum[j] += inq_result[4][j][0]\n",
    "            if(inq_result[4][j][1] == inqs[2]):\n",
    "                Hit_itself_sum[j] += 1\n",
    "            \n",
    "    top_cat_same = [x/Total_run for x in Tops_same_count]\n",
    "    top_cat_same_hit = [x/Total_run for x in Tops_same_ever_hit]\n",
    "    Nth_score_avg = [x/Total_run for x in Nth_score_sum]\n",
    "    Hit_itself_avg = [x/Total_run for x in Hit_itself_sum]\n",
    "    \n",
    "    print(top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg)\n",
    "    \n",
    "    return (top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.67, 1.07, 1.28, 1.5, 1.68], [0.67, 0.72, 0.75, 0.78, 0.78], [1468.9675286393074, 1990.4723390313206, 2219.1774095071487, 2314.7653604314573, 2373.6116836425554], [0.0, 0.0, 0.0, 0.0, 0.0])\n"
     ]
    }
   ],
   "source": [
    "(top_cat_same,top_cat_same_hit, Nth_score_avg, Hit_itself_avg) = multiple_test(data, run_times=100, if_itself=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 100 yes\n",
    "# # ([1.0, 1.6, 1.9, 2.11, 2.31], \n",
    "# [1.0, 1.0, 1.0, 1.0, 1.0], \n",
    "# [477.99725810013655, 1569.801293508719, 1983.8946612704194, 2173.4673165842296, 2239.76024740403],\n",
    "# [1.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # 100 No it self\n",
    "# ([0.67, 1.07, 1.28, 1.5, 1.68], \n",
    "#  [0.67, 0.72, 0.75, 0.78, 0.78], \n",
    "#  [1468.9675286393074, 1990.4723390313206, 2219.1774095071487, 2314.7653604314573, 2373.6116836425554],\n",
    "#  [0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl]",
   "language": "python",
   "name": "conda-env-dl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
