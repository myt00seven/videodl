{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple test for inquiry model\n",
    "\n",
    "\n",
    "Here is the setting:\n",
    "\n",
    "- My thought: Yintai Ma [09:23] \n",
    "  - Suppose I have a video X of 100 frames, denoting as X[0] to X[99]. We then split it to multiple clips without overlap. If then length of each clip is 5 frames, then we come up with a sequences of clips X[0:5],X[5:10],...,X[95:100]. We use the encoder to transfer the sequences of clips to sequences of embeddeds, reads y[0],y[1],...,y[20]. Now we randomly pick some frames from X as validation clip and transfer it into validation embedded y_hat. We want to see how y_hat is matching to the sequences of y[0]...y[20].\n",
    "\n",
    "- Diego:\n",
    "  - You have video X. Randomly pick  sequences of frames (non overlapping). Say x[4:10], x[34:37],x[85:95]. Now concatenate them into a single video. This is now your query. From here, create embedding sequence y[0],â€¦y[K]. Now do DTW of y against your encoded sequences of the videos in the database.\n",
    "  - This is subject to experimentation. I agree that there should be overlap. Overlap by half.\n",
    "\n",
    "- My thought: There are many variations for the implementation:\n",
    "  1. we keep overlaps for y. We transfer X[0:5],X[1:6],....X[94:99],X[95:100] into y[0]...y[100]. Now we want to see how y_hat is matching to y[].\n",
    "  2. When we pick some frames from X to composite validation clips, do we always pick 5 consecutive frames? Should we ever transfer X[0]+X[2:6] into y_hat?\n",
    "  3. How we match y_hat to y[] if y_hat is also a sequences? I think this is where DTW comes in right? If y_hat is just one embedded, then what we need is basically a simple comparison between the distance of two embedded. However, if y_hat is a sequences, say it has y_hat[0] and y_hat[1], then we will need to use DTW to consider the case where both y_hat[0] matches to y[0] and y_hat[1] matches to y[3] are the best query retrieve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/lab.analytics.northwestern.edu/yma/.conda/envs/py3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, LSTM, RepeatVector\n",
    "from keras.layers.wrappers import *\n",
    "from keras.layers.core import *\n",
    "from keras.layers.convolutional import Conv3D\n",
    "from keras.layers.convolutional_recurrent import ConvLSTM2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.optimizers import RMSprop\n",
    "from keras import backend as K\n",
    "\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpngw\n",
    "import pandas as pd \n",
    "\n",
    "from IPython.display import HTML\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENERATE_DATA = 1 \n",
    "LOG_DIR = \"../../tensorboard/log/\"\n",
    "EPOCH = 150\n",
    "sequenceLength = 3\n",
    "setup_name = \"clrmvsq_simple_vgg_a\"\n",
    "N_SAMPLES = 1000\n",
    "BATCHSIZE = 5\n",
    "ucf_generate_fps = 2  # The fps to sample from the original UCF data to generate the train and val set\n",
    "data_path = \"../../data/UCF/\"\n",
    "\n",
    "batch_size=20\n",
    "data_type = 'images'\n",
    "concat=False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-3-55990598bef0>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-55990598bef0>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    print data.data[:1], '\\n'\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "import data_seq\n",
    "data_seq = reload(data_seq)\n",
    "\n",
    "data = data_seq.DataSet(seq_length=5,class_limit=10)\n",
    "\n",
    "print data.data[:1], '\\n'\n",
    "print data.classes[:5]\n",
    "print data.image_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = data.seq_generator(batch_size, 'train', 'images')\n",
    "\n",
    "X,y  = next(generator);\n",
    "\n",
    "print X.shape\n",
    "\n",
    "images = X[18]\n",
    "imageio.mimsave('./movie.gif', images)\n",
    "HTML('<img src=\"./movie.gif\">')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y  = next(generator);\n",
    "for i in range (0,5):\n",
    "    images = X[i][0]\n",
    "    plt.imshow(images)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    X,y  = next(generator);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X,y  = next(generator);\n",
    "\n",
    "print X.shape\n",
    "\n",
    "images = X[18]\n",
    "imageio.mimsave('./movie.gif', images)\n",
    "HTML('<img src=\"./movie.gif\">')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(os.path.expanduser('/home/lab.analytics.northwestern.edu/yma/git/videodl/seq_inquiry'))\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Examaine model file\n",
    "from keras.models import load_model\n",
    "\n",
    "# weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_seq3_convlstm.040-0.0857.hdf5\"\n",
    "\n",
    "weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_vgg16_simple_seq3_convlstm.001-0.03.hdf5\"\n",
    "\n",
    "model = load_model(weights_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Start Assembling the Model ---\")\n",
    "\n",
    "inputs = Input(shape=(sequenceLength,224,224,3))\n",
    "\n",
    "# conved = TimeDistributed(Lambda(MyCNN), input_shape=(sequenceLength,40,40,1)) (inputs)\n",
    "\n",
    "x = TimeDistributed(Conv2D(64, (3, 3), padding='same', activation='relu', name='block1_conv1'), input_shape=(sequenceLength,224,224,3))(inputs)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block1_pool'))(x)\n",
    "# x = TimeDistributed(MaxPooling2D((2, 2)))(x)\n",
    "x = TimeDistributed(Conv2D(128, (3, 3), padding='same', activation='relu', name='block2_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block2_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(256, (3, 3), padding='same', activation='relu', name='block3_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block3_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block4_conv1'))(x)\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block4_pool'))(x)\n",
    "x = TimeDistributed(Conv2D(512, (3, 3), padding='same', activation='relu', name='block5_conv1'))(x)\n",
    "\n",
    "# LSTM part\n",
    "x = TimeDistributed(MaxPooling2D((2, 2), name='block5_pool'))(x)\n",
    "# x = TimeDistributed(Flatten())(x)\n",
    "\n",
    "encoded = ConvLSTM2D(filters=100, kernel_size=(3, 3),padding='same', return_sequences=True)(x)\n",
    "\n",
    "encoder = Model(output=encoded,input=inputs)\n",
    "# myoptmizer = RMSprop(lr=0.1, decay=1e-4)\n",
    "# autoencoder.compile(loss='mean_squared_error', optimizer=myoptmizer)\n",
    "encoder.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "plot_model(encoder, to_file='query_model.png', show_shapes=True)\n",
    "\n",
    "print('--- Finish Compile and Plot Model ---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights_file = \"/home/lab.analytics.northwestern.edu/yma/git/data/checkpoints/ucf_simple_vgg16_seq3_convlstm_c5.002-0.0186.hdf5\"\n",
    "encoder.load_weights(weights_file, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Start from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_database(data):\n",
    "    database = []\n",
    "    for i in range(0, N_database):\n",
    "        smp = data.data[i]\n",
    "        vid_len = int(smp[3])\n",
    "        frams = data.get_frames_for_sample(smp)\n",
    "        frams = data.rescale_list(frams, vid_len-1)\n",
    "        seq = data.build_image_sequence(frams)\n",
    "        seq = np.array(seq)\n",
    "        \n",
    "        seqX = []\n",
    "        for j in range(0,len(seq)-SEQ_LENGTH, (SEQ_LENGTH>>1)+1):\n",
    "            seqX.append(seq[j:j+SEQ_LENGTH])\n",
    "        seqX = np.array(seqX)\n",
    "        seqY = encoder.predict(seqX)\n",
    "        database.append((seqY, smp[2]))\n",
    "    return database\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def get_random_inquiry(data, if_random=True):\n",
    "    if if_random:\n",
    "        smp = random.choice(data.data)\n",
    "    else:\n",
    "        smp = data.data[0]\n",
    "    \n",
    "    vid_len = int(smp[3])\n",
    "    frams = data.get_frames_for_sample(smp)\n",
    "    frams = data.rescale_list(frams, vid_len-1)\n",
    "    seq = data.build_image_sequence(frams)\n",
    "    seq = np.array(seq)\n",
    "    \n",
    "    seqX = []\n",
    "    X_frames_start= []\n",
    "    stepsize = vid_len / inq_length - 2\n",
    "    for j in range(0, inq_length):\n",
    "        jst = j*stepsize\n",
    "        jend = j*stepsize+SEQ_LENGTH\n",
    "        seqX.append(seq[jst:jend])\n",
    "        X_frames_start.append((jst, jend))\n",
    "    seqX = np.array(seqX)\n",
    "    seqY = encoder.predict(seqX)\n",
    "    return (seqX, seqY ,smp[2], X_frames_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inquiry_in_database(inquiry_seqY, database):\n",
    "    scores= []\n",
    "    score_names = []\n",
    "    bestscore = 1<<30\n",
    "#     dist, cost, acc, path\n",
    "    for i in database:\n",
    "#         print(inquiry_seqY.shape)\n",
    "#         print(i[0].shape)\n",
    "        seqyflat = inquiry_seqY.reshape((inquiry_seqY.shape[0], 3*7*7*100))\n",
    "        iyflat = i[0].reshape((i[0].shape[0], 3*7*7*100))\n",
    "#         print(seqyflat.shape)\n",
    "#         print(iyflat.shape)\n",
    "        dist, cost, acc, path = dtw(seqyflat, iyflat, dist=lambda x, y: np.linalg.norm(x - y, ord=1))\n",
    "        scores.append((dist,i[1]))\n",
    "        if dist< bestscore:\n",
    "            bestscore = dist\n",
    "            bestpath = path\n",
    "            bestacc= acc\n",
    "            bestfilename = i[1]\n",
    "    scores = sorted(scores, key=lambda x:x[0])\n",
    "    return (bestscore, bestacc, bestpath, bestfilename, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_seq\n",
    "from scipy.spatial.distance import euclidean\n",
    "from dtw import dtw\n",
    "%pylab inline\n",
    "\n",
    "data_seq = reload(data_seq)\n",
    "SEQ_LENGTH = 3\n",
    "# the number of frames in each clip\n",
    "\n",
    "data = data_seq.DataSet(seq_length=SEQ_LENGTH,class_limit=20, random_class=True)\n",
    "random.shuffle(data.data)\n",
    "N_database = 100\n",
    "\n",
    "inq_length = 8\n",
    "# the number of clips in the inquiry, no overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "database = create_database(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inqs = get_random_inquiry(data, True)\n",
    "seqY = inqs[1]\n",
    "\n",
    "inq_result = inquiry_in_database(seqY, database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Inqury is:\\t\"+ inqs[2])\n",
    "print(\"Inqury frames:\\t\"+ str(inqs[3]))\n",
    "print(\"Best Match is:\\t\"+ inq_result[3])\n",
    "print(\"Best Dist:\\t\"+ str(inq_result[0]))\n",
    "\n",
    "acc = inq_result[1]\n",
    "path = inq_result[2]\n",
    "imshow(acc.T, origin='lower', cmap=cm.gray, interpolation='nearest')\n",
    "plot(path[0], path[1], 'w')\n",
    "# xlim((-0.5, acc.shape[0]-0.5))\n",
    "# ylim((-0.5, acc.shape[1]-0.5))\n",
    "\n",
    "print(\"========================\")\n",
    "print(\"All scores in database:\")\n",
    "for i in range(len(inq_result[4])):\n",
    "    print(\"Record: \"+ inq_result[4][i][1].ljust(25)+ \"\\tDTW Dist: \"+ str(inq_result[4][i][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
